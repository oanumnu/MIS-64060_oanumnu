---
title: "Assignment_2_ML1"
author: "Obianuju Anumnu"
date: "October 4, 2020"
output:
  html_document:
    df_print: paged
---

```{r}
#import data set 
Bank <- read.csv("D:/Machine/Assignment2/UniversalBank.csv")
head(Bank)
summary(Bank)
#convert all variables to the right format
library(caret)
Bank$Personal.Loan<- as.factor(Bank$Personal.Loan)
library(dummies)
dummy_model<-dummyVars(~Education, data=Bank)
head(predict(dummy_model,Bank))
Bank_dummy <-dummy.data.frame(Bank, names =c("Education"), sep="-")
UB<-subset(Bank_dummy,select = -c(1, 5))
head(UB)


```

```{r}
#split the data 
set.seed(15)
Train_Index <-createDataPartition(UB$Personal.Loan,p=0.6, list = FALSE)
#use 60% for training and the rest for validation
Train <-UB[Train_Index,]
Valid <- UB[-Train_Index,]

#copy original data
train.norm.df<-Train
valid.norm.df<-Valid

#normalize data
norm.values<-preProcess(Train[,-10], method = c("range"))
train.norm.df[,-10] <- predict(norm.values,Train[,-10])
valid.norm.df[,-10]<-predict(norm.values,Valid[,-10])

#Modelling using k=1
library(FNN)
nn <- knn(train = train.norm.df[, -10], test = valid.norm.df[, -10], 
          cl = train.norm.df[, 10], k = 1, prob=TRUE)
#view predicted class
head(nn)
```


```{r}
#value of k that provides the best performance
library(caret)
accuracy.df <-data.frame(k= seq(1,14,1), accuracy = rep(0,14))
for(i in 1:14) {
                  knn <- knn(train.norm.df[, -10], valid.norm.df[, -10], cl = train.norm.df[, 10], k = i)
                  accuracy.df[i, 2] <- confusionMatrix(knn, valid.norm.df[, 10])$overall[1] 
                }
accuracy.df
which.max((accuracy.df$accuracy))

#the best choice of k is 3 at 0.9560
```


```{r}
#develop test data
L_Predictors<-UB[,-10]
L_labels<-UB[,10]
Test <- data.frame(40, 10, 84, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1)
colnames(Test) <- colnames(L_Predictors)
Test.norm.df <- Test
head(Test.norm.df)

#combine Train and Valid set, renormalise using this new set
Traval.norm.df <- UB
norm.values <- preProcess(UB[,-10], method = c("range"))
Traval.norm.df[,-10]<-predict(norm.values, UB[,-10])
Test.norm.df<-predict(norm.values, Test)

#Predicting using k=1
nn <- knn(train = Traval.norm.df[, -10], test = Test.norm.df, 
          cl = Traval.norm.df[, 10], k = 1, prob=TRUE)
#view predicted class
head(nn)
# customer is classified as zero, customer will not accept the loan

#Predicting using k=3
nn <- knn(train = Traval.norm.df[, -10], test = Test.norm.df, 
          cl = Traval.norm.df[, 10], k = 3, prob=TRUE)
#view predicted class
head(nn)
# customer is also classified as zero, customer will not accept the loan

```

```{r}
#Show the confusion matrix for the validation data that results from using the best k.
knn.valid <- knn(train.norm.df[, -10],valid.norm.df[, -10],cl=train.norm.df[, 10],k=3,prob = 0.5)
confusionMatrix(knn.valid, valid.norm.df[, 10])
# error types 
#True Negative - 1794
#False Negative - 14
#True Positive - 118
#false Positive - 74
#sensitivity(TPR) - TP/(TP+FN) = 118/(118+14) = 0.8939
#specificity(TNR) - TN/(TN+FP) = 1794/(1794+74) = 0.9603

```

```{r}
#modelling with diff partitioning -  training, validation, and test sets (50% : 30% : 20%)

#split the data 
set.seed(15)
Train_Index_2 <-createDataPartition(UB$Personal.Loan,p=0.5, list = FALSE)
#use 50% for training and the rest for validation and test
Train_2 <-UB[Train_Index_2,]
ValTest <- UB[-Train_Index_2,]
Valid_Index  <- createDataPartition(ValTest$Personal.Loan,p=0.6, list = FALSE)
Valid_2 <- ValTest[Valid_Index,]
Test_2 <- ValTest[-Valid_Index,]


#copy original data
train_2.norm.df<-Train_2
valid_2.norm.df<-Valid_2
test_2.norm.df <-Test_2

#normalize data
norm.values_2<-preProcess(Train_2[,-10], method = c("center", "scale"))
train_2.norm.df[,-10] <- predict(norm.values_2,Train_2[,-10])
valid_2.norm.df[,-10]<-predict(norm.values_2,Valid_2[,-10])
test_2.norm.df[,-10]<-predict(norm.values_2,Test_2[,-10])


#Modelling using k=3 for testset
library(FNN)
nn_2 <- knn(train = train_2.norm.df[, -10], test = test_2.norm.df[, -10], 
          cl = train_2.norm.df[, 10], k = 3, prob=TRUE)
#view predicted class
head(nn_2)



#Modelling using k=3 for validation set
nn_2_valid<- knn(train = train_2.norm.df[, -10], test = valid_2.norm.df[, -10], 
          cl = train_2.norm.df[, 10], k = 3, prob=TRUE)
#view predicted class
head(nn_2_valid)
#compare confusion matrix for test set with validation set
confusionMatrix(nn_2, test_2.norm.df[, 10])
#Accuracy for Test is 0.956
confusionMatrix(nn_2_valid, valid_2.norm.df[, 10])
#Accuracy for validation is 0.954

#the test set has a higher confusion matrix
```

```{r}

```


```{r}

```
  
                 
    


